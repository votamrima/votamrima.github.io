---
layout: single
title: "Node Maintenance Tasks"
subtitle: ""
date: 2025-03-16 08:15:00 +0100
background: '/image/01.jpg'
tags: ['kubernetes']
---

{% raw %}

This is the some note about the performing basic maintenance tasks in Kubernetes cluster. 

### Metrics Server

Metrics Server doesn't install on Kubernetes from the box. We need to install it seperately from the official github repository - https://github.com/kubernetes-sigs/metrics-server 

````bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
````

Once installation is finished, you can see that pod is running, but no container is up:

````bash
seymur@fedora40:~$ kubectl -n kube-system get pods
NAME                                            READY   STATUS    RESTARTS        AGE
.....
metrics-server-54bf7cdd6-8sr98                  0/1     Running   0               2m13s
````

Here you need to configure the Metric Server deployment to allow insecure tls. To solve this I edited the deployment:
````bash
kubectl -n kube-system edit deployments.apps metrics-server
````

and added ``--kubelet-insecure-tls`` parameter:

````bash
spec:
      containers:
      - args:
        - --kubelet-insecure-tls
````

After that the single container was run successfull.

To check if metrics server does what it should do, run the following command:

````bash
seymur@fedora40:~$ kubectl top pods
NAME                          CPU(cores)   MEMORY(bytes)   
mypod-kube-worker1.home.lab   0m           4Mi             
````



### Kubernetes Cluster Update

Kubernetes is able to upgrade from another minor version to anothe minor version. Skipping the version is not supported. For example, directly upgrade from 1.29 to 1.32 is not supported without upgrade to 1.30 and 1.31.

Here is the basic steps to proceed the upgrade:
- Upgrade kubeadm
- Update Kubernetes repository in ``/etc/yum.repos.d/kubernetes.repo``
- First are upgraded control nodes, second - worker nodes. It is not necessary to upgrade all immediately. You are able to run different versions some time.
- Use official documentation: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/


- Here I updated the current version of the repository:

````bash
baseurl=https://pkgs.k8s.io/core:/stable:/v1.32/rpm/
````

#### kubeadm upgrade
Print the versions of all available versions of kubeadm:

````bash
sudo yum list --showduplicates kubeadm --disableexcludes=kubernetes
````

Installing the latest version which is available for now.

````bash
yum install kubeadm-'1.32.3-*' --disableexcludes=kubernetes
````

Verifying the current version

````bash
[root@kube-master1 ~]# kubeadm version
kubeadm version: &version.Info{Major:"1", Minor:"32", GitVersion:"v1.32.3", GitCommit:"32cc146f75aad04beaaa245a7157eb35063a9f99", GitTreeState:"clean", BuildDate:"2025-03-11T19:57:38Z", GoVersion:"go1.23.6", Compiler:"gc", Platform:"linux/amd64"}
````

#### Running upgrade of the control node

- Preparing upgrade plan:
````bash
kubeadm upgrade plan
````
- Running upgrade. It took for me max 5 minutes. 

````bash
kubeadm upgrade apply v1.32.3
.....

[upgrade] SUCCESS! A control plane node of your cluster was upgraded to "v1.32.3".
````

All these steps should be proceeded on each control node.

Once the upgrade of nodes finished, check from the admin host using ``kubectl`` the current version of the nodes.

````bash
seymur@fedora40:~$ kubectl get nodes
NAME                    STATUS   ROLES           AGE    VERSION
kube-master1.home.lab   Ready    control-plane   125d   v1.31.2
kube-master2.home.lab   Ready    control-plane   125d   v1.31.2
kube-master3.home.lab   Ready    control-plane   125d   v1.31.2
kube-worker1.home.lab   Ready    worker          125d   v1.31.2
kube-worker2.home.lab   Ready    worker          125d   v1.31.2
kube-worker3.home.lab   Ready    worker          125d   v1.31.2
````

It is still the previous version. In order to solve the issue, you should upgrade the kubelet and kubectl on the node VM.

#### Update kubelet and kubectl

Mark the node as unschedulable to set the node in maintenance

````bash
seymur@fedora40:~$ kubectl drain kube-master1.home.lab --ignore-daemonsets
````

Upgrade required packages

````bash
yum install -y kubelet-'1.32.3-*' kubectl-'1.32.3-*' --disableexcludes=kubernetes
````

Reload the kubelet service on the

````bash
systemctl daemon-reload
systemctl restart kubelet
````

Bring the node back online by marking it schedulable:

````bash
kubectl uncordon kube-master1.home.lab
````

#### Upgrade of worker nodes
Detailed documentation: https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/upgrading-linux-nodes/

1. Update the yum repo file
2. Update kubeadm

````bash
yum install -y kubeadm-'1.32.3-*' --disableexcludes=kubernetes
````

3. Upgrade node

````bash
kubeadm upgrade node
````

3. Drainin the host in order to set the node into maintenance

````bash
seymur@fedora40:~$ kubectl drain kube-worker1.home.lab --ignore-daemonsets 
````

4. Updating the kubelet and kubeadm

````bash
[root@kube-worker1 ~]# yum install -y kubelet-'1.32.3-*' kubectl-'1.32.3-*' --disableexcludes=kubernetes 
````

5. Reload daemon and restart kubelet

````bash
[root@kube-worker1 ~]# systemctl daemon-reload
[root@kube-worker1 ~]# systemctl restart kubelet
````

6. Uncording the worker node

````bash
seymur@fedora40:~$ kubectl uncordon kube-worker3.home.lab 
````



````bash
````
````bash
````
````bash
````
````bash
````
````bash
````
````bash
````
````bash
````
````bash
````



{% endraw %}

